#!/usr/bin/python2.7
"""
Creates an attributes file of Twitter where each node is a Twitter user. The
value of a node is the average response time to retweet by that user.
"""

#BIGDATA

from __future__ import print_function
from __future__ import unicode_literals
from __future__ import absolute_import
from __future__ import division

import sys
import re
import argparse
import time


# Shows processing progress
def write_progress(mapname, i, n, done=False):
    sys.stderr.write("\rProcessing '{}' {:,}/{:,} ({}%)..."
            .format(mapname, i, n, int(i/n * 100)))
    if done:
        sys.stderr.write(" Done.\n")


re_timestamp = re.compile("^T\t(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})$")
re_user      = re.compile("^U\t.*?/([^/\n]+)$")
re_message   = re.compile("^W\t(.*)$")

def read_tweet(f):
    """Reads in a single tweet from the given file stream."""
    line = f.readline()
    if line:
        timestamp = re_timestamp.match(line).group(1)
        timestamp = time.mktime(time.strptime(timestamp, "%Y-%m-%d %H:%M:%S"))
        line = f.readline()
        if line:
            user = re_user.match(line).group(1)
            line = f.readline()
            if line:
                message = re_message.match(line).group(1)
                return (timestamp, user.lower(), message)

    return None

# Iterates over tweets
def twitter(f):
    """Iterates over the tweets in the given file stream."""
    t = read_tweet(f)
    while t:
        yield t
        f.readline() # Tweets are separated by a line
        t = read_tweet(f)


# Find mentioned people
re_mention = re.compile("@(\w+)")
def mentioned(message):
    """Iterates over the people mentioned in a tweet."""
    return re_mention.finditer(message)


def read_usercount(f):
    """Reads the highest user index from the given file stream."""
    f.seek(-128, 2)
    last = f.readlines()[-1].decode()
    n, _ = last.split(" ", 1)
    n = int(n)
    f.seek(0)
    return n

def read_usermap(f, n):
    """Reads the dictionary of users to IDs."""

    # Dictionary of username -> ID
    user_map = {}

    # Load the map of IDs to usernames
    write_progress(f.name, 0, n)

    for line in f:
        i, name = line.decode('utf-8').rstrip().split(" ", 1)
        i = int(i)
        user_map[name.lower()] = i
        if i % 150000 == 0:
            write_progress(f.name, i, n)

    write_progress(f.name, n, n, done=True)

    return user_map


re_header = re.compile("total number:(\d+)")
re_retweet = re.compile("RT @(\w+):? (.*)")

def read_tweets(f, user_map, messages, nodes):
    i = 0

    # Read the header ("total number:X")
    tweet_count = int(re_header.match(f.readline()).group(1))

    for ts,user,message in twitter(f):
        # Display status message
        if i % 10000 == 0:
            write_progress(f.name, i, tweet_count)

        h = hash(message)
        if not (h in messages):
            messages[h] = { user: ts }
        else:
            messages[h][user] = ts

        # Found a retweeted message?
        m = re_retweet.match(message)
        if m:
            mention, retweet = m.group(1).lower(), hash(m.group(2))

            # Found the retweeted message
            if (mention != user and (retweet in messages) and
                    (mention in messages[retweet]) and (user in user_map)):
                userid = user_map[user]
                response_time = (ts - messages[retweet][mention]) + nodes[userid]
                if response_time > 0 and response_time < 60*60*24*30:
                    # Keep a running average
                    nodes[userid] = (nodes[userid] + normalize(response_time)) / 2
        i += 1

    write_progress(f.name, i, tweet_count, done=True)


def normalize(response_time):
    """Normalizes the user's retweet response time."""
    from math import log
    return log(response_time, 2)


# Command line arguments
parser = argparse.ArgumentParser(description='Processes tweets.')
parser.add_argument('files', nargs='*', type=argparse.FileType('r'),
        default=[sys.stdin], help='Tweets.')
parser.add_argument('--usermap', type=argparse.FileType('rb'),
        help='Map of user IDs to names.')

def main():
    # Parse command line arguments.
    args = parser.parse_args()

    # Find the number of users
    args.usermap.seek(-128, 2)
    last = args.usermap.readlines()[-1].decode('utf-8')
    user_count, _ = last.split(" ", 1)
    user_count = int(user_count)
    args.usermap.seek(0)

    user_count = read_usercount(args.usermap)

    sys.stderr.write("Found {:,} Twitter users.\n".format(user_count))

    user_map = read_usermap(args.usermap, user_count)

    # User response times
    nodes = [0] * user_count

    # Dictionary of hashed messages -> { user: timestamp }
    messages = {}

    # Build the list of nodes
    for f in args.files:
        read_tweets(f, user_map, messages, nodes)

    # Write out the node data to standard output.
    sys.stderr.write("Writing data...")
    i = 0
    for t in nodes:
        if t > 0: # 0 means the user has not responded to any tweets
            sys.stdout.write(str(i) + "," + str(t) + "\n")
        i += 1
    sys.stderr.write(" Done.\n")
    sys.stdout.flush()


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("Processing aborted.", file=sys.stderr)
        pass
